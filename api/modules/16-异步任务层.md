# 16-异步任务层

## 概述

异步任务层（`tasks/`）负责处理系统中的各种异步任务，包括文档索引、邮件发送、数据处理等耗时操作。该层基于Celery任务队列系统，提供并发处理、任务状态跟踪、错误重试等功能，确保系统的响应性和可靠性。

## 目录结构

```
tasks/
├── __init__.py                                    # 任务模块初始化
├── add_document_to_index_task.py                  # 添加文档到索引任务
├── document_indexing_task.py                      # 文档索引任务
├── document_indexing_sync_task.py                 # 文档索引同步任务
├── document_indexing_update_task.py               # 文档索引更新任务
├── duplicate_document_indexing_task.py            # 文档索引复制任务
├── enable_segment_to_index_task.py                # 启用段索引任务
├── disable_segment_from_index_task.py             # 禁用段索引任务
├── delete_segment_from_index_task.py              # 删除段索引任务
├── batch_create_segment_to_index_task.py          # 批量创建段索引任务
├── batch_clean_document_task.py                   # 批量清理文档任务
├── clean_document_task.py                         # 清理文档任务
├── clean_dataset_task.py                          # 清理数据集任务
├── deal_dataset_vector_index_task.py              # 处理数据集向量索引任务
├── remove_document_from_index_task.py             # 从索引移除文档任务
├── retry_document_indexing_task.py                # 重试文档索引任务
├── recover_document_indexing_task.py              # 恢复文档索引任务
├── sync_website_document_indexing_task.py         # 同步网站文档索引任务
├── mail_invite_member_task.py                     # 邀请成员邮件任务
├── mail_reset_password_task.py                    # 重置密码邮件任务
├── mail_change_mail_task.py                       # 修改邮箱邮件任务
├── mail_email_code_login.py                       # 邮箱验证码登录任务
├── mail_owner_transfer_task.py                    # 所有者转移邮件任务
├── mail_account_deletion_task.py                  # 账户删除邮件任务
├── mail_enterprise_task.py                        # 企业邮件任务
├── remove_app_and_related_data_task.py            # 移除应用和相关数据任务
├── delete_account_task.py                         # 删除账户任务
├── process_tenant_plugin_autoupgrade_check_task.py # 租户插件自动升级检查任务
├── ops_trace_task.py                              # 运维追踪任务
├── clean_notion_document_task.py                  # 清理Notion文档任务
└── annotation/                                     # 注释相关任务
    ├── add_annotation_to_index_task.py            # 添加注释到索引任务
    ├── update_annotation_to_index_task.py         # 更新注释索引任务
    ├── delete_annotation_index_task.py            # 删除注释索引任务
    ├── enable_annotation_reply_task.py            # 启用注释回复任务
    ├── disable_annotation_reply_task.py           # 禁用注释回复任务
    └── batch_import_annotations_task.py           # 批量导入注释任务
```

## 核心任务详解

### 1. `add_document_to_index_task.py` - 添加文档到索引任务

**职责**: 将处理完成的文档添加到向量索引中，支持父子文档结构。

**核心功能**:
```python
@shared_task(queue="dataset")
def add_document_to_index_task(dataset_document_id: str):
    """异步添加文档到索引"""
    logging.info(click.style("Start add document to index: {}".format(dataset_document_id), fg="green"))
    start_at = time.perf_counter()

    # 获取文档信息
    dataset_document = db.session.query(DatasetDocument).filter(
        DatasetDocument.id == dataset_document_id
    ).first()
    
    if not dataset_document:
        logging.info(click.style("Document not found: {}".format(dataset_document_id), fg="red"))
        db.session.close()
        return

    if dataset_document.indexing_status != "completed":
        return

    indexing_cache_key = "document_{}_indexing".format(dataset_document.id)

    try:
        dataset = dataset_document.dataset
        if not dataset:
            raise Exception(f"Document {dataset_document.id} dataset {dataset_document.dataset_id} doesn't exist.")

        # 获取文档段
        segments = (
            db.session.query(DocumentSegment)
            .filter(
                DocumentSegment.document_id == dataset_document.id,
                DocumentSegment.enabled == False,
                DocumentSegment.status == "completed",
            )
            .order_by(DocumentSegment.position.asc())
            .all()
        )

        # 构建文档对象
        documents = []
        for segment in segments:
            document = Document(
                page_content=segment.content,
                metadata={
                    "doc_id": segment.index_node_id,
                    "doc_hash": segment.index_node_hash,
                    "document_id": segment.document_id,
                    "dataset_id": segment.dataset_id,
                },
            )
            
            # 处理父子文档结构
            if dataset_document.doc_form == IndexType.PARENT_CHILD_INDEX:
                child_chunks = segment.get_child_chunks()
                if child_chunks:
                    child_documents = []
                    for child_chunk in child_chunks:
                        child_document = ChildDocument(
                            page_content=child_chunk.content,
                            metadata={
                                "doc_id": child_chunk.index_node_id,
                                "doc_hash": child_chunk.index_node_hash,
                                "document_id": segment.document_id,
                                "dataset_id": segment.dataset_id,
                            },
                        )
                        child_documents.append(child_document)
                    document.children = child_documents
            documents.append(document)

        # 加载到索引
        index_type = dataset.doc_form
        index_processor = IndexProcessorFactory(index_type).init_index_processor()
        index_processor.load(dataset, documents)

        # 清理自动禁用日志
        db.session.query(DatasetAutoDisableLog).filter(
            DatasetAutoDisableLog.document_id == dataset_document.id
        ).delete()

        # 更新段状态为启用
        db.session.query(DocumentSegment).filter(
            DocumentSegment.document_id == dataset_document.id
        ).update({
            DocumentSegment.enabled: True,
            DocumentSegment.disabled_at: None,
            DocumentSegment.disabled_by: None,
            DocumentSegment.updated_at: datetime.datetime.now(datetime.UTC).replace(tzinfo=None),
        })
        db.session.commit()

        end_at = time.perf_counter()
        logging.info(
            click.style(
                "Document added to index: {} latency: {}".format(dataset_document.id, end_at - start_at), fg="green"
            )
        )
    except Exception as e:
        logging.exception("add document to index failed")
        # 错误处理：禁用文档并记录错误
        dataset_document.enabled = False
        dataset_document.disabled_at = datetime.datetime.now(datetime.UTC).replace(tzinfo=None)
        dataset_document.indexing_status = "error"
        dataset_document.error = str(e)
        db.session.commit()
    finally:
        redis_client.delete(indexing_cache_key)
```

**设计特点**:
- 支持父子文档结构
- 批量处理文档段
- 错误处理和状态回滚
- 缓存清理机制

### 2. `mail_invite_member_task.py` - 邀请成员邮件任务

**职责**: 异步发送邀请成员邮件，支持国际化。

**核心功能**:
```python
@shared_task(queue="mail")
def send_invite_member_mail_task(language: str, to: str, token: str, inviter_name: str, workspace_name: str) -> None:
    """发送邀请成员邮件"""
    if not mail.is_inited():
        return

    logging.info(
        click.style("Start send invite member mail to {} in workspace {}".format(to, workspace_name), fg="green")
    )
    start_at = time.perf_counter()

    try:
        # 构建激活链接
        url = f"{dify_config.CONSOLE_WEB_URL}/activate?token={token}"
        email_service = get_email_i18n_service()
        
        # 发送邮件
        email_service.send_email(
            email_type=EmailType.INVITE_MEMBER,
            language_code=language,
            to=to,
            template_context={
                "to": to,
                "inviter_name": inviter_name,
                "workspace_name": workspace_name,
                "url": url,
            },
        )

        end_at = time.perf_counter()
        logging.info(
            click.style(
                "Send invite member mail to {} succeeded: latency: {}".format(to, end_at - start_at), fg="green"
            )
        )
    except Exception:
        logging.exception("Send invite member mail to {} failed".format(to))
```

**设计特点**:
- 国际化支持
- 邮件服务检查
- 性能监控
- 错误处理

### 3. `annotation/enable_annotation_reply_task.py` - 启用注释回复任务

**职责**: 启用应用的注释回复功能，将注释数据添加到向量索引。

**核心功能**:
```python
@shared_task(queue="dataset")
def enable_annotation_reply_task(
    job_id: str,
    app_id: str,
    user_id: str,
    tenant_id: str,
    score_threshold: float,
    embedding_provider_name: str,
    embedding_model_name: str,
):
    """异步启用注释回复任务"""
    logging.info(click.style("Start add app annotation to index: {}".format(app_id), fg="green"))
    start_at = time.perf_counter()
    
    # 获取应用信息
    app = db.session.query(App).filter(
        App.id == app_id, 
        App.tenant_id == tenant_id, 
        App.status == "normal"
    ).first()

    if not app:
        logging.info(click.style("App not found: {}".format(app_id), fg="red"))
        db.session.close()
        return

    annotations = db.session.query(MessageAnnotation).filter(
        MessageAnnotation.app_id == app_id
    ).all()
    
    enable_app_annotation_key = "enable_app_annotation_{}".format(str(app_id))
    enable_app_annotation_job_key = "enable_app_annotation_job_{}".format(str(job_id))

    try:
        documents = []
        dataset_collection_binding = DatasetCollectionBindingService.get_dataset_collection_binding(
            embedding_provider_name, embedding_model_name, "annotation"
        )
        
        # 更新或创建注释设置
        annotation_setting = (
            db.session.query(AppAnnotationSetting).filter(
                AppAnnotationSetting.app_id == app_id
            ).first()
        )
        
        if annotation_setting:
            # 如果向量模型发生变化，清理旧索引
            if dataset_collection_binding.id != annotation_setting.collection_binding_id:
                old_dataset_collection_binding = (
                    DatasetCollectionBindingService.get_dataset_collection_binding_by_id_and_type(
                        annotation_setting.collection_binding_id, "annotation"
                    )
                )
                if old_dataset_collection_binding and annotations:
                    old_dataset = Dataset(
                        id=app_id,
                        tenant_id=tenant_id,
                        indexing_technique="high_quality",
                        embedding_model_provider=old_dataset_collection_binding.provider_name,
                        embedding_model=old_dataset_collection_binding.model_name,
                        collection_binding_id=old_dataset_collection_binding.id,
                    )

                    old_vector = Vector(old_dataset, attributes=["doc_id", "annotation_id", "app_id"])
                    try:
                        old_vector.delete()
                    except Exception as e:
                        logging.info(click.style("Delete annotation index error: {}".format(str(e)), fg="red"))
            
            # 更新设置
            annotation_setting.score_threshold = score_threshold
            annotation_setting.collection_binding_id = dataset_collection_binding.id
            annotation_setting.updated_user_id = user_id
            annotation_setting.updated_at = datetime.datetime.now(datetime.UTC).replace(tzinfo=None)
            db.session.add(annotation_setting)
        else:
            # 创建新设置
            new_app_annotation_setting = AppAnnotationSetting(
                app_id=app_id,
                score_threshold=score_threshold,
                collection_binding_id=dataset_collection_binding.id,
                created_user_id=user_id,
                updated_user_id=user_id,
            )
            db.session.add(new_app_annotation_setting)

        # 构建数据集和向量对象
        dataset = Dataset(
            id=app_id,
            tenant_id=tenant_id,
            indexing_technique="high_quality",
            embedding_model_provider=embedding_provider_name,
            embedding_model=embedding_model_name,
            collection_binding_id=dataset_collection_binding.id,
        )
        
        # 构建文档对象
        if annotations:
            for annotation in annotations:
                document = Document(
                    page_content=annotation.question,
                    metadata={
                        "doc_id": annotation.id,
                        "annotation_id": annotation.id,
                        "app_id": app_id,
                        "content": annotation.content,
                    },
                )
                documents.append(document)

        # 加载到向量索引
        if documents:
            vector = Vector(dataset, attributes=["doc_id", "annotation_id", "app_id"])
            vector.add_texts(documents)

        db.session.commit()
        
        end_at = time.perf_counter()
        logging.info(
            click.style(
                "App annotation added to index: {} latency: {}".format(app_id, end_at - start_at), fg="green"
            )
        )
    except Exception as e:
        logging.exception("Enable annotation reply failed")
        raise
    finally:
        redis_client.delete(enable_app_annotation_key)
        redis_client.delete(enable_app_annotation_job_key)
```

**设计特点**:
- 支持向量模型切换
- 自动清理旧索引
- 批量处理注释数据
- 缓存管理

## 任务分类和队列

### 1. 任务分类

**文档处理任务**:
- 文档索引相关任务
- 段索引管理任务
- 批量处理任务

**邮件任务**:
- 邀请邮件
- 密码重置邮件
- 账户管理邮件

**注释任务**:
- 注释索引管理
- 注释回复功能
- 批量导入注释

**系统维护任务**:
- 数据清理任务
- 账户删除任务
- 应用移除任务

### 2. 队列配置

```python
# 不同任务使用不同的队列
QUEUE_CONFIG = {
    "dataset": {
        "concurrency": 4,  # 文档处理并发数
        "max_tasks_per_child": 1000,
        "task_acks_late": True,
    },
    "mail": {
        "concurrency": 2,  # 邮件发送并发数
        "max_tasks_per_child": 500,
        "task_acks_late": False,
    },
    "annotation": {
        "concurrency": 2,  # 注释处理并发数
        "max_tasks_per_child": 500,
    },
    "default": {
        "concurrency": 2,
        "max_tasks_per_child": 500,
    },
}
```

## 任务设计原则

### 1. 设计特点

**幂等性**:
- 任务可以重复执行而不产生副作用
- 支持任务重试机制

**可配置性**:
- 通过参数控制任务行为
- 支持环境特定的配置

**监控和日志**:
- 详细的任务执行日志
- 性能监控和统计
- 错误追踪和报告

### 2. 错误处理

**重试机制**:
```python
@shared_task(
    queue="dataset",
    bind=True,
    max_retries=3,
    default_retry_delay=60
)
def retryable_task(self, *args, **kwargs):
    """可重试的任务"""
    try:
        # 任务逻辑
        process_data()
    except Exception as exc:
        # 重试任务
        self.retry(exc=exc, countdown=60)
```

**状态管理**:
```python
def update_task_status(task_id: str, status: str, error: str = None):
    """更新任务状态"""
    task_status = {
        "status": status,
        "updated_at": datetime.now(),
        "error": error
    }
    redis_client.setex(f"task_status:{task_id}", 3600, json.dumps(task_status))
```

## 使用示例

### 1. 提交任务

```python
from tasks.add_document_to_index_task import add_document_to_index_task
from tasks.mail_invite_member_task import send_invite_member_mail_task

# 提交文档索引任务
task = add_document_to_index_task.delay(document_id)

# 提交邮件任务
mail_task = send_invite_member_mail_task.delay(
    language="en-US",
    to="user@example.com",
    token="invitation_token",
    inviter_name="John Doe",
    workspace_name="My Workspace"
)
```

### 2. 任务状态监控

```python
from celery.result import AsyncResult

# 检查任务状态
result = AsyncResult(task.id)
print(f"Task status: {result.status}")

# 获取任务结果
if result.ready():
    if result.successful():
        print(f"Task completed: {result.get()}")
    else:
        print(f"Task failed: {result.info}")
```

### 3. 批量任务处理

```python
from celery import group

# 批量提交任务
document_ids = ["doc1", "doc2", "doc3"]
tasks = group(add_document_to_index_task.s(doc_id) for doc_id in document_ids)
result = tasks.apply_async()

# 等待所有任务完成
result.get()
```

## 最佳实践

### 1. 任务设计原则

**单一职责**:
- 每个任务只负责一个特定功能
- 避免任务间的相互依赖

**资源管理**:
- 正确关闭数据库连接
- 清理临时资源
- 使用上下文管理器

**错误处理**:
- 提供详细的错误信息
- 支持任务重试
- 记录错误日志

### 2. 性能优化

**批量处理**:
```python
def batch_process_documents(document_ids: List[str], batch_size: int = 100):
    """批量处理文档"""
    for i in range(0, len(document_ids), batch_size):
        batch = document_ids[i:i + batch_size]
        # 处理批次
        process_batch(batch)
```

**缓存使用**:
```python
def get_cached_data(key: str):
    """获取缓存数据"""
    cached = redis_client.get(key)
    if cached:
        return json.loads(cached)
    
    # 从数据库获取
    data = fetch_from_database()
    redis_client.setex(key, 3600, json.dumps(data))
    return data
```

### 3. 监控和调试

**任务监控**:
```python
def monitor_task_execution(task_name: str):
    """监控任务执行"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            start_time = time.time()
            try:
                result = func(*args, **kwargs)
                execution_time = time.time() - start_time
                logging.info(f"Task {task_name} completed in {execution_time:.2f}s")
                return result
            except Exception as e:
                execution_time = time.time() - start_time
                logging.error(f"Task {task_name} failed after {execution_time:.2f}s: {e}")
                raise
        return wrapper
    return decorator
```

## 扩展指南

### 添加新任务

1. **创建任务文件**:
```python
# tasks/new_task.py
import logging
import time
import click
from celery import shared_task

@shared_task(queue="dataset")
def new_task(param1: str, param2: int):
    """新异步任务"""
    logging.info(click.style("Start new task", fg="green"))
    start_at = time.perf_counter()
    
    try:
        # 任务逻辑
        result = process_data(param1, param2)
        
        end_at = time.perf_counter()
        logging.info(
            click.style(f"New task completed: latency: {end_at - start_at}", fg="green")
        )
        return result
    except Exception as e:
        logging.exception("New task failed")
        raise
```

2. **注册任务**:
```python
# 在__init__.py中导入
from .new_task import new_task
```

3. **配置队列**:
```python
# 在队列配置中添加
QUEUE_CONFIG["new_queue"] = {
    "concurrency": 2,
    "max_tasks_per_child": 500,
}
```

### 自定义任务装饰器

```python
def custom_task(queue_name: str, max_retries: int = 3):
    """自定义任务装饰器"""
    def decorator(func):
        @shared_task(
            queue=queue_name,
            bind=True,
            max_retries=max_retries,
            default_retry_delay=60
        )
        def wrapper(self, *args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as exc:
                logging.exception(f"Task {func.__name__} failed")
                self.retry(exc=exc, countdown=60)
        return wrapper
    return decorator
```

## 故障排除

### 常见问题

1. **任务执行失败**
   - 检查任务日志
   - 验证参数正确性
   - 确认依赖服务可用

2. **队列积压**
   - 增加工作进程数
   - 优化任务执行时间
   - 检查任务依赖关系

3. **内存泄漏**
   - 定期重启工作进程
   - 检查资源清理
   - 监控内存使用

### 调试技巧

```python
import logging

logger = logging.getLogger(__name__)

def debug_task_execution(task_name: str):
    """调试任务执行"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger.debug(f"开始执行任务: {task_name}")
            logger.debug(f"任务参数: {args}, {kwargs}")
            
            try:
                result = func(*args, **kwargs)
                logger.debug(f"任务 {task_name} 执行成功")
                return result
            except Exception as e:
                logger.error(f"任务 {task_name} 执行失败: {e}")
                raise
        return wrapper
    return decorator
```

---

*异步任务层为Dify提供了可靠的后台处理能力，确保系统的响应性和可扩展性，支持复杂的业务逻辑和数据处理需求。* 