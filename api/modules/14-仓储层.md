# 14-仓储层

## 概述

仓储层（`repositories/`）负责数据访问和持久化操作，采用仓储模式（Repository Pattern）封装数据访问逻辑。该层提供统一的数据访问接口，支持查询优化、缓存策略、多租户隔离等功能，确保数据访问的一致性和性能。

## 目录结构

```
repositories/
├── __init__.py                                    # 仓储模块初始化
├── factory.py                                     # 仓储工厂
├── api_workflow_run_repository.py                 # 工作流运行仓储接口
├── api_workflow_node_execution_repository.py      # 工作流节点执行仓储接口
├── sqlalchemy_api_workflow_run_repository.py      # SQLAlchemy工作流运行仓储实现
└── sqlalchemy_api_workflow_node_execution_repository.py # SQLAlchemy工作流节点执行仓储实现
```

## 核心组件详解

### 1. `factory.py` - 仓储工厂

**职责**: 负责创建和管理仓储实例，支持依赖注入和配置驱动。

**核心功能**:
```python
class DifyAPIRepositoryFactory(DifyCoreRepositoryFactory):
    """DifyAPI仓储工厂"""
    
    @classmethod
    def create_api_workflow_node_execution_repository(
        cls, session_maker: sessionmaker
    ) -> DifyAPIWorkflowNodeExecutionRepository:
        """创建工作流节点执行仓储实例"""
        class_path = dify_config.API_WORKFLOW_NODE_EXECUTION_REPOSITORY
        logger.debug(f"Creating DifyAPIWorkflowNodeExecutionRepository from: {class_path}")

        try:
            repository_class = cls._import_class(class_path)
            cls._validate_repository_interface(repository_class, DifyAPIWorkflowNodeExecutionRepository)
            cls._validate_constructor_signature(repository_class, ["session_maker"])

            return repository_class(session_maker=session_maker)
        except RepositoryImportError:
            raise
        except Exception as e:
            logger.exception("Failed to create DifyAPIWorkflowNodeExecutionRepository")
            raise RepositoryImportError(
                f"Failed to create DifyAPIWorkflowNodeExecutionRepository from '{class_path}': {e}"
            ) from e

    @classmethod
    def create_api_workflow_run_repository(cls, session_maker: sessionmaker) -> APIWorkflowRunRepository:
        """创建工作流运行仓储实例"""
        class_path = dify_config.API_WORKFLOW_RUN_REPOSITORY
        logger.debug(f"Creating APIWorkflowRunRepository from: {class_path}")

        try:
            repository_class = cls._import_class(class_path)
            cls._validate_repository_interface(repository_class, APIWorkflowRunRepository)
            cls._validate_constructor_signature(repository_class, ["session_maker"])

            return repository_class(session_maker=session_maker)
        except RepositoryImportError:
            raise
        except Exception as e:
            logger.exception("Failed to create APIWorkflowRunRepository")
            raise RepositoryImportError(f"Failed to create APIWorkflowRunRepository from '{class_path}': {e}") from e
```

**设计特点**:
- 配置驱动的仓储创建
- 依赖注入支持
- 接口验证和类型检查
- 错误处理和日志记录

### 2. `api_workflow_run_repository.py` - 工作流运行仓储接口

**职责**: 定义工作流运行相关的数据访问接口。

**核心接口**:
```python
class APIWorkflowRunRepository(WorkflowExecutionRepository, Protocol):
    """工作流运行仓储协议"""
    
    def get_paginated_workflow_runs(
        self,
        tenant_id: str,
        app_id: str,
        triggered_from: str,
        limit: int = 20,
        last_id: Optional[str] = None,
    ) -> InfiniteScrollPagination:
        """
        获取分页工作流运行记录
        
        Args:
            tenant_id: 租户标识符
            app_id: 应用标识符
            triggered_from: 触发来源过滤
            limit: 最大返回记录数
            last_id: 分页游标
            
        Returns:
            InfiniteScrollPagination对象，包含数据和分页信息
        """
        ...
    
    def get_workflow_run_by_id(
        self,
        tenant_id: str,
        app_id: str,
        run_id: str,
    ) -> Optional[WorkflowRun]:
        """
        根据ID获取工作流运行记录
        
        Args:
            tenant_id: 租户标识符
            app_id: 应用标识符
            run_id: 运行记录ID
            
        Returns:
            工作流运行记录，如果不存在则返回None
        """
        ...
    
    def get_expired_runs_batch(
        self,
        tenant_id: str,
        before_date: datetime,
        batch_size: int = 1000,
    ) -> Sequence[WorkflowRun]:
        """
        获取过期的运行记录批次
        
        Args:
            tenant_id: 租户标识符
            before_date: 过期时间点
            batch_size: 批次大小
            
        Returns:
            过期运行记录列表
        """
        ...
    
    def delete_runs_by_ids(
        self,
        run_ids: Sequence[str],
    ) -> int:
        """
        根据ID列表删除运行记录
        
        Args:
            run_ids: 运行记录ID列表
            
        Returns:
            删除的记录数量
        """
        ...
    
    def delete_runs_by_app(
        self,
        tenant_id: str,
        app_id: str,
        batch_size: int = 1000,
    ) -> int:
        """
        删除应用的所有运行记录
        
        Args:
            tenant_id: 租户标识符
            app_id: 应用标识符
            batch_size: 批次大小
            
        Returns:
            删除的记录数量
        """
        ...
```

### 3. `api_workflow_node_execution_repository.py` - 工作流节点执行仓储接口

**职责**: 定义工作流节点执行相关的数据访问接口。

**核心接口**:
```python
class DifyAPIWorkflowNodeExecutionRepository(WorkflowNodeExecutionRepository, Protocol):
    """工作流节点执行仓储协议"""
    
    def get_node_executions_by_run_id(
        self,
        tenant_id: str,
        run_id: str,
    ) -> Sequence[WorkflowNodeExecution]:
        """
        根据运行ID获取节点执行记录
        
        Args:
            tenant_id: 租户标识符
            run_id: 运行记录ID
            
        Returns:
            节点执行记录列表
        """
        ...
    
    def get_node_execution_by_id(
        self,
        tenant_id: str,
        execution_id: str,
    ) -> Optional[WorkflowNodeExecution]:
        """
        根据ID获取节点执行记录
        
        Args:
            tenant_id: 租户标识符
            execution_id: 执行记录ID
            
        Returns:
            节点执行记录，如果不存在则返回None
        """
        ...
    
    def create_node_execution(
        self,
        tenant_id: str,
        run_id: str,
        node_id: str,
        node_type: str,
        inputs: dict,
        outputs: Optional[dict] = None,
        status: str = "pending",
    ) -> WorkflowNodeExecution:
        """
        创建节点执行记录
        
        Args:
            tenant_id: 租户标识符
            run_id: 运行记录ID
            node_id: 节点ID
            node_type: 节点类型
            inputs: 输入数据
            outputs: 输出数据
            status: 执行状态
            
        Returns:
            创建的节点执行记录
        """
        ...
    
    def update_node_execution(
        self,
        tenant_id: str,
        execution_id: str,
        **updates,
    ) -> Optional[WorkflowNodeExecution]:
        """
        更新节点执行记录
        
        Args:
            tenant_id: 租户标识符
            execution_id: 执行记录ID
            **updates: 更新字段
            
        Returns:
            更新后的节点执行记录
        """
        ...
```

### 4. SQLAlchemy实现

**职责**: 提供基于SQLAlchemy的具体仓储实现。

**核心实现**:
```python
class SQLAlchemyAPIWorkflowRunRepository(APIWorkflowRunRepository):
    """SQLAlchemy工作流运行仓储实现"""
    
    def __init__(self, session_maker: sessionmaker):
        self.session_maker = session_maker
    
    def get_paginated_workflow_runs(
        self,
        tenant_id: str,
        app_id: str,
        triggered_from: str,
        limit: int = 20,
        last_id: Optional[str] = None,
    ) -> InfiniteScrollPagination:
        """获取分页工作流运行记录"""
        with self.session_maker() as session:
            query = session.query(WorkflowRun).filter(
                WorkflowRun.tenant_id == tenant_id,
                WorkflowRun.app_id == app_id,
                WorkflowRun.triggered_from == triggered_from
            ).order_by(WorkflowRun.created_at.desc())
            
            if last_id:
                last_run = session.query(WorkflowRun).filter(
                    WorkflowRun.id == last_id
                ).first()
                if not last_run:
                    raise ValueError(f"Last run with ID {last_id} not found")
                query = query.filter(WorkflowRun.created_at < last_run.created_at)
            
            runs = query.limit(limit + 1).all()
            has_more = len(runs) > limit
            if has_more:
                runs = runs[:-1]
            
            return InfiniteScrollPagination(
                data=runs,
                limit=limit,
                has_more=has_more
            )
    
    def delete_runs_by_ids(self, run_ids: Sequence[str]) -> int:
        """根据ID列表删除运行记录"""
        with self.session_maker() as session:
            # 备份到OSS（如果配置了）
            if dify_config.ENABLE_WORKFLOW_RUN_BACKUP:
                self._backup_runs_to_oss(session, run_ids)
            
            # 删除记录
            deleted_count = session.query(WorkflowRun).filter(
                WorkflowRun.id.in_(run_ids)
            ).delete(synchronize_session=False)
            
            session.commit()
            return deleted_count
```

## 仓储模式设计

### 1. 设计原则

**单一职责**:
- 每个仓储只负责一个实体类型的数据访问
- 避免跨实体的复杂查询逻辑

**依赖倒置**:
- 定义接口，实现依赖注入
- 服务层依赖仓储接口而非具体实现

**多租户支持**:
- 所有查询都包含租户隔离
- 确保数据安全性

### 2. 查询优化

**索引策略**:
```python
# 常用查询字段建立索引
class WorkflowRun(Base):
    __tablename__ = 'workflow_runs'
    
    # 复合索引：租户 + 应用 + 创建时间
    __table_args__ = (
        Index('idx_tenant_app_created', 'tenant_id', 'app_id', 'created_at'),
        Index('idx_tenant_triggered', 'tenant_id', 'triggered_from'),
    )
```

**分页优化**:
```python
def get_paginated_data(self, tenant_id: str, limit: int, last_id: str = None):
    """优化的分页查询"""
    query = self.session.query(Model).filter(
        Model.tenant_id == tenant_id
    ).order_by(Model.created_at.desc())
    
    if last_id:
        # 使用游标分页，避免OFFSET的性能问题
        last_record = self.session.query(Model).filter(
            Model.id == last_id
        ).first()
        if last_record:
            query = query.filter(Model.created_at < last_record.created_at)
    
    return query.limit(limit + 1).all()
```

### 3. 缓存策略

**Redis缓存**:
```python
class CachedRepository:
    """带缓存的仓储"""
    
    def __init__(self, repository, redis_client):
        self.repository = repository
        self.redis_client = redis_client
    
    def get_by_id(self, tenant_id: str, id: str):
        """带缓存的ID查询"""
        cache_key = f"workflow_run:{tenant_id}:{id}"
        
        # 尝试从缓存获取
        cached_data = self.redis_client.get(cache_key)
        if cached_data:
            return json.loads(cached_data)
        
        # 从数据库查询
        data = self.repository.get_by_id(tenant_id, id)
        if data:
            # 缓存结果
            self.redis_client.setex(
                cache_key, 
                3600,  # 1小时过期
                json.dumps(data.to_dict())
            )
        
        return data
```

## 使用示例

### 1. 仓储创建和使用

```python
from repositories.factory import DifyAPIRepositoryFactory
from sqlalchemy.orm import sessionmaker

# 创建仓储实例
session_maker = sessionmaker(bind=db.engine, expire_on_commit=False)
workflow_run_repo = DifyAPIRepositoryFactory.create_api_workflow_run_repository(session_maker)

# 获取分页数据
pagination = workflow_run_repo.get_paginated_workflow_runs(
    tenant_id="tenant-123",
    app_id="app-456",
    triggered_from="debugging",
    limit=20
)

for run in pagination.data:
    print(f"Workflow Run: {run.id}, Status: {run.status}")
```

### 2. 批量操作

```python
# 批量删除过期记录
from datetime import datetime, timedelta

expired_date = datetime.utcnow() - timedelta(days=30)
expired_runs = workflow_run_repo.get_expired_runs_batch(
    tenant_id="tenant-123",
    before_date=expired_date,
    batch_size=1000
)

if expired_runs:
    run_ids = [run.id for run in expired_runs]
    deleted_count = workflow_run_repo.delete_runs_by_ids(run_ids)
    print(f"Deleted {deleted_count} expired workflow runs")
```

### 3. 节点执行管理

```python
# 创建节点执行仓储
node_execution_repo = DifyAPIRepositoryFactory.create_api_workflow_node_execution_repository(session_maker)

# 创建节点执行记录
execution = node_execution_repo.create_node_execution(
    tenant_id="tenant-123",
    run_id="run-456",
    node_id="node-789",
    node_type="llm",
    inputs={"prompt": "Hello, world!"},
    status="running"
)

# 更新执行状态
updated_execution = node_execution_repo.update_node_execution(
    tenant_id="tenant-123",
    execution_id=execution.id,
    status="completed",
    outputs={"response": "Hello, AI!"}
)
```

## 最佳实践

### 1. 仓储设计原则

**接口分离**:
- 为不同的业务场景定义专门的接口
- 避免接口过于复杂

**事务管理**:
- 在仓储层处理事务边界
- 确保数据一致性

**错误处理**:
- 提供详细的错误信息
- 支持优雅的错误恢复

### 2. 性能优化

**查询优化**:
```python
def optimized_query(self, tenant_id: str):
    """优化的查询方法"""
    # 使用select_from避免N+1查询
    return self.session.query(WorkflowRun).options(
        joinedload(WorkflowRun.node_executions)
    ).filter(
        WorkflowRun.tenant_id == tenant_id
    ).all()
```

**批量操作**:
```python
def batch_insert(self, records: List[dict]):
    """批量插入"""
    with self.session_maker() as session:
        session.bulk_insert_mappings(WorkflowRun, records)
        session.commit()
```

### 3. 测试支持

```python
class MockWorkflowRunRepository(APIWorkflowRunRepository):
    """工作流运行仓储的Mock实现"""
    
    def __init__(self):
        self.runs = {}
    
    def get_paginated_workflow_runs(self, tenant_id: str, app_id: str, **kwargs):
        """Mock分页查询"""
        filtered_runs = [
            run for run in self.runs.values()
            if run.tenant_id == tenant_id and run.app_id == app_id
        ]
        return InfiniteScrollPagination(
            data=filtered_runs[:kwargs.get('limit', 20)],
            limit=kwargs.get('limit', 20),
            has_more=len(filtered_runs) > kwargs.get('limit', 20)
        )
```

## 扩展指南

### 添加新仓储

1. **定义接口**:
```python
# repositories/new_repository.py
from typing import Protocol, Optional, Sequence

class NewRepository(Protocol):
    """新仓储接口"""
    
    def get_by_id(self, tenant_id: str, id: str) -> Optional[NewModel]:
        """根据ID获取记录"""
        ...
    
    def create(self, tenant_id: str, data: dict) -> NewModel:
        """创建记录"""
        ...
    
    def update(self, tenant_id: str, id: str, **updates) -> Optional[NewModel]:
        """更新记录"""
        ...
```

2. **实现仓储**:
```python
# repositories/sqlalchemy_new_repository.py
class SQLAlchemyNewRepository(NewRepository):
    """SQLAlchemy新仓储实现"""
    
    def __init__(self, session_maker: sessionmaker):
        self.session_maker = session_maker
    
    def get_by_id(self, tenant_id: str, id: str) -> Optional[NewModel]:
        with self.session_maker() as session:
            return session.query(NewModel).filter(
                NewModel.tenant_id == tenant_id,
                NewModel.id == id
            ).first()
```

3. **注册到工厂**:
```python
# 在factory.py中添加创建方法
@classmethod
def create_new_repository(cls, session_maker: sessionmaker) -> NewRepository:
    """创建新仓储实例"""
    class_path = dify_config.NEW_REPOSITORY
    repository_class = cls._import_class(class_path)
    return repository_class(session_maker=session_maker)
```

### 自定义查询方法

```python
class CustomQueryRepository:
    """自定义查询仓储"""
    
    def get_complex_data(self, tenant_id: str, filters: dict):
        """复杂查询方法"""
        with self.session_maker() as session:
            query = session.query(Model).filter(Model.tenant_id == tenant_id)
            
            # 应用过滤条件
            if filters.get('status'):
                query = query.filter(Model.status == filters['status'])
            
            if filters.get('date_range'):
                start_date, end_date = filters['date_range']
                query = query.filter(
                    Model.created_at.between(start_date, end_date)
                )
            
            return query.all()
```

## 故障排除

### 常见问题

1. **性能问题**
   - 检查查询是否使用了索引
   - 避免N+1查询问题
   - 使用批量操作

2. **内存泄漏**
   - 确保正确关闭数据库会话
   - 使用上下文管理器
   - 避免长时间持有会话

3. **并发问题**
   - 使用适当的事务隔离级别
   - 处理并发更新冲突
   - 实现乐观锁机制

### 调试技巧

```python
import logging

logger = logging.getLogger(__name__)

def debug_repository_operation(operation_name: str):
    """调试仓储操作"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger.debug(f"执行仓储操作: {operation_name}, 参数: {args}, {kwargs}")
            try:
                result = func(*args, **kwargs)
                logger.debug(f"仓储操作 {operation_name} 执行成功")
                return result
            except Exception as e:
                logger.error(f"仓储操作 {operation_name} 执行失败: {e}")
                raise
        return wrapper
    return decorator
```

---

*仓储层为Dify提供了统一、高效的数据访问机制，确保数据操作的一致性和性能，支持系统的可扩展性和可维护性。* 